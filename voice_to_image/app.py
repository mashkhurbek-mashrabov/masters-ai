import os
import base64
import streamlit as st
from dotenv import load_dotenv
from st_audiorec import st_audiorec
from agent import VoiceToImageAgent

load_dotenv()

st.set_page_config(page_title="Voice to Image", page_icon="ğŸ™ï¸", layout="centered")

st.title("ğŸ™ï¸ Voice to Image")
st.markdown(
    "Record a short voice message describing an image you'd like to create. "
    "The agent will transcribe your speech, craft a detailed prompt, and generate the image."
)

with st.sidebar:
    st.header("âš™ï¸ Configuration")
    api_key = st.text_input(
        "OpenAI API Key",
        type="password",
        value=os.getenv("OPENAI_API_KEY", ""),
        help="Required. Get yours at https://platform.openai.com/api-keys",
    )
    st.divider()
    st.subheader("Models used")
    st.markdown("- **Speech-to-Text:** `whisper-1`")
    st.markdown("- **LLM (prompt crafting):** `gpt-4o-mini`")
    st.markdown("- **Image generation:** `dall-e-3`")

st.subheader("1ï¸âƒ£ Record your voice message")
audio_bytes = st_audiorec()

st.subheader("Or upload an audio file")
uploaded_file = st.file_uploader(
    "Upload a .wav or .mp3 file",
    type=["wav", "mp3", "m4a", "ogg", "webm"],
)

if uploaded_file is not None:
    audio_bytes = uploaded_file.read()
    st.audio(audio_bytes)

st.divider()
generate = st.button("ğŸš€ Generate Image", type="primary", use_container_width=True)

if generate:
    if not api_key:
        st.error("Please provide your OpenAI API key in the sidebar.")
        st.stop()
    if audio_bytes is None:
        st.error("Please record or upload an audio message first.")
        st.stop()

    agent = VoiceToImageAgent(api_key=api_key)

    with st.status("Processing...", expanded=True) as status:
        st.write("ğŸ”Š **Step 1/3** â€” Transcribing audio with `whisper-1`...")
        transcript = agent.transcribe(audio_bytes)
        st.write("âœ… Transcription complete.")

        st.write("ğŸ§  **Step 2/3** â€” Generating image prompt with `gpt-4o-mini`...")
        image_prompt = agent.generate_image_prompt(transcript)
        st.write("âœ… Image prompt ready.")

        st.write("ğŸ¨ **Step 3/3** â€” Generating image with `dall-e-3`...")
        image_b64 = agent.generate_image(image_prompt)
        st.write("âœ… Image generated!")

        status.update(label="Pipeline complete!", state="complete", expanded=True)

    st.divider()

    st.subheader("2ï¸âƒ£ Transcription")
    st.info(transcript)

    st.subheader("3ï¸âƒ£ Generated Image Prompt")
    st.success(image_prompt)

    st.subheader("4ï¸âƒ£ Generated Image")
    image_data = base64.b64decode(image_b64)
    st.image(image_data, caption="Generated by DALL-E 3", use_container_width=True)

    st.download_button(
        label="ğŸ’¾ Download Image",
        data=image_data,
        file_name="generated_image.png",
        mime="image/png",
    )

    st.divider()
    st.subheader("ğŸ“‹ Pipeline Summary")
    col1, col2, col3 = st.columns(3)
    col1.metric("STT Model", "whisper-1")
    col2.metric("LLM Model", "gpt-4o-mini")
    col3.metric("Image Model", "dall-e-3")
